# Agente LLM con Conexi√≥n a SQLite

Este proyecto consiste en un agente inteligente que combina **consultas SQL**, **b√∫squeda web** y
**razonamiento natural** usando un **modelo LLM local o remoto** con API tipo OpenAI.

## Estructura del proyecto

    agent_project/
    ‚îÇ
    ‚îú‚îÄ‚îÄ backend/
    ‚îÇ   ‚îú‚îÄ‚îÄ main.py
    ‚îÇ   ‚îú‚îÄ‚îÄ router.py
    ‚îÇ   ‚îú‚îÄ‚îÄ llm_client.py
    ‚îÇ   ‚îú‚îÄ‚îÄ db_client.py
    ‚îÇ   ‚îú‚îÄ‚îÄ web_search.py
    ‚îÇ   ‚îú‚îÄ‚îÄ prompts.py
    ‚îÇ   ‚îî‚îÄ‚îÄ config.py
    ‚îÇ
    ‚îú‚îÄ‚îÄ frontend/
    ‚îÇ   ‚îî‚îÄ‚îÄ app.py
    ‚îÇ
    ‚îú‚îÄ‚îÄ database.db (SQLite)
    ‚îú‚îÄ‚îÄ requirements.txt
    ‚îî‚îÄ‚îÄ README.md

## Instalaci√≥n

### 1. Crear entorno virtual

Este proyecto se creo sobre un entorno virtual con python 3.10
``` bash
python -m venv .venv
source .venv/bin/activate   # Linux/Mac
.venv\Scripts\activate    # Windows
```

### 2. Instalar dependencias

``` bash
pip install -r requirements.txt
```

### 3. Configurar .env

    LLM_PROVIDER="local"  # "openai" | "gemini" | "local" | "lmstudio"

    LLM_API_BASE=http://localhost:8001/v1
    LLM_MODEL=model_name

    LLM_API_KEY=""
    OPENAI_API_KEY=""
    GEMINI_API_KEY=""

    TAVILY_API_KEY=""

    DB_PATH=./database.db

### 4. Levantar backend

Se levanta un servicio FastAPI
``` bash
uvicorn backend.main:app --reload --port 8000
```

### 5. Levantar frontend

Se levanta un frontend con el framework Streamlit
``` bash
streamlit run frontend/app.py
```

### 6. üß† C√≥mo funciona el agente

1. User ‚Üí mensaje textual
2. FastAPI ‚Üí Router decide intenci√≥n via LLM
3. Seg√∫n la intenci√≥n:
   - **sql** ‚Üí genera SQL, ejecuta, resume resultados
   - **web** ‚Üí busca info con Tavily, resume, devuelve fuentes
   - **llm** ‚Üí respuesta directa del modelo
4. Devue lve JSON a Streamlit
5. Streamlit muestra la respuesta y renderiza tablas o fuentes


### 7. Ejemplos de uso

#### Consulta SQL

> "Dame un top de los datos de la tabla <tabla> por fecha"
> "Cu√°les son los detalles del campo <campo> de la tabla <tabla>"

#### Web search

> "¬øCu√°les son los trending topics?"
> "¬øCu√°l es la noticia m√°s reciente de la ciudad de m√©xico?"
> "Dime el pronostico del tiempo de Quintana Roo"

#### Respuesta LLM

> "Explica qu√© es un SLA."
> "¬øQu√© es la IA?"


### 8. Pasos Siguientes
> Integraciones con bases vectoriales
> Integraci√≥n de memoria contextual para mantener un chat conversacional
> Integraci√≥n con servicio de embeddings para busquedas en bases de conocimientos
> Integraciones con servicios de otras APIs, ejecuci√≥n de tareas.


